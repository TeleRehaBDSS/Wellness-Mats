import ast
import os
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Tuple

import cv2
import numpy as np
import pandas as pd
from scipy.ndimage import median_filter


@dataclass
class BasicMatSignals:
    """Container for basic signals derived from one mat CSV."""

    time_s: np.ndarray          # shape (T,)
    force: np.ndarray           # total force (sum of all sensors), shape (T,)
    cop_x: np.ndarray           # center of pressure (column index units), shape (T,)
    cop_y: np.ndarray           # center of pressure (row index units), shape (T,)
    dt: float                   # median sampling period (seconds)
    area: np.ndarray            # number of active sensors (contact area proxy), shape (T,)
    frames: np.ndarray          # Full 3D sensor data: (T, rows, cols)


@dataclass
class ExerciseResult:
    participant: str
    exercise: str
    variant: Optional[str]      # direction / side, e.g. BACKWARD, LEFT, RIGHT
    file_path: str
    score: int                  # MiniBEST-style 0â€“2
    features: Dict[str, float]


# ---------------------------
# Low-level data utilities
# ---------------------------

def _parse_sensors_column(df: pd.DataFrame) -> np.ndarray:
    """
    Parse the 'sensors' column (stringified 2D list) into a 3D numpy array.

    Returns array of shape (T, rows, cols).
    """
    if "sensors" not in df.columns:
        raise ValueError("CSV does not contain 'sensors' column.")

    sensors_list: List[List[List[float]]] = []
    for raw in df["sensors"]:
        # Each entry looks like: "[[0, 0, ...], [...], ...]"
        sensors_list.append(ast.literal_eval(raw))

    sensors_arr = np.array(sensors_list, dtype=float)
    if sensors_arr.ndim != 3:
        raise ValueError(f"Expected sensors array with 3 dims, got shape {sensors_arr.shape}")
    return sensors_arr


def load_basic_signals(csv_path: str) -> BasicMatSignals:
    """Load one mat CSV and compute basic signals: total force and CoP."""
    df = pd.read_csv(csv_path)

    # Sort by timepoint to fix disordered rows/negative dt
    if "timepoint" in df.columns:
        df["timepoint"] = pd.to_datetime(df["timepoint"])
        df = df.sort_values("timepoint").reset_index(drop=True)

    # Time in seconds from start of trial
    if "timepoint" not in df.columns:
        raise ValueError("CSV does not contain 'timepoint' column.")
    
    time = df["timepoint"]
    time_s = (time - time.iloc[0]).dt.total_seconds().to_numpy()

    sensors = _parse_sensors_column(df)
    
    # Apply noise threshold to sensors
    # Zero out very small pressures that might be background noise
    sensors[sensors < 2.0] = 0.0
    
    # sensors: (T, rows, cols)
    rows = sensors.shape[1]
    cols = sensors.shape[2]

    # Total force per sample
    force = sensors.sum(axis=(1, 2))

    # Contact area proxy: number of sensors above a small threshold
    area_threshold = 1e-3
    area = (sensors > area_threshold).sum(axis=(1, 2))

    # Center of pressure (index units, not physical units)
    row_indices = np.arange(rows).reshape(1, rows, 1)
    col_indices = np.arange(cols).reshape(1, 1, cols)

    # Avoid division by zero
    eps = 1e-6
    cop_y = (sensors * row_indices).sum(axis=(1, 2)) / (force + eps)
    cop_x = (sensors * col_indices).sum(axis=(1, 2)) / (force + eps)

    # Handle NaN/Inf in CoP caused by zero force frames
    # Set to 0 or interpolate? For now, just keeping them as is, 
    # but we should probably mask them later.
    cop_y[force < 1e-3] = np.nan
    cop_x[force < 1e-3] = np.nan

    # Median sampling interval
    if len(time_s) > 1:
        diffs = np.diff(time_s)
        valid_diffs = diffs[diffs > 0.0001]
        if len(valid_diffs) > 0:
            dt = float(np.median(valid_diffs))
        else:
            dt = 0.01
    else:
        dt = 0.01

    return BasicMatSignals(
        time_s=time_s,
        force=force,
        cop_x=cop_x,
        cop_y=cop_y,
        dt=dt,
        area=area,
        frames=sensors
    )


def _sway_metrics(cop_x: np.ndarray, cop_y: np.ndarray) -> Dict[str, float]:
    """Compute simple sway metrics from CoP trajectory."""
    # Use only finite points
    mask = np.isfinite(cop_x) & np.isfinite(cop_y)
    if not mask.any():
        return {"cop_path_length": float("nan"), "cop_rms": float("nan")}

    x = cop_x[mask]
    y = cop_y[mask]
    # Path length
    dx = np.diff(x)
    dy = np.diff(y)
    path = float(np.sum(np.sqrt(dx * dx + dy * dy)))
    # RMS distance from mean
    x0 = x - x.mean()
    y0 = y - y.mean()
    rms = float(np.sqrt(np.mean(x0 * x0 + y0 * y0)))
    return {"cop_path_length": path, "cop_rms": rms}


def _duration(signals: BasicMatSignals) -> float:
    return float(signals.time_s[-1] - signals.time_s[0]) if len(signals.time_s) > 1 else 0.0


def _stance_balance_metrics(signals: BasicMatSignals) -> Dict[str, float]:
    """
    Compute stance-specific metrics that are shared between
    eyes open / eyes closed variants.

    This helper focuses on *quality* of stance rather than duration:
    - Number of balance-loss episodes
    - Average pressure per active sensor
    - Baseline contact area
    """
    force = signals.force.astype(float)
    area = signals.area.astype(float)
    dt = max(signals.dt, 1e-4)

    # Consider frames with meaningful force as "on the mat"
    active_force_thresh = 10.0
    active_mask = force > active_force_thresh

    # Average pressure per active sensor (force / number of active sensors)
    valid_pressure_mask = active_mask & (area > 0)
    if np.any(valid_pressure_mask):
        pressure_per_sensor = force[valid_pressure_mask] / area[valid_pressure_mask]
        avg_pressure_per_sensor = float(np.mean(pressure_per_sensor))
    else:
        avg_pressure_per_sensor = float("nan")

    # Baseline contact area during stance (use median to be robust to outliers)
    if np.any(valid_pressure_mask):
        baseline_area = float(np.median(area[valid_pressure_mask]))
    else:
        baseline_area = float("nan")

    # Heuristic "loss of balance" detector:
    # Flag frames where area or force drops substantially relative to baseline.
    if np.any(active_mask):
        median_force = float(np.median(force[active_mask]))
    else:
        median_force = 0.0

    # If we do not have a sensible baseline, we will treat all frames as stable.
    if np.isfinite(baseline_area) and baseline_area > 0 and median_force > 0:
        low_area_thresh = 0.7 * baseline_area
        low_force_thresh = 0.5 * median_force
        loss_mask = active_mask & ((area < low_area_thresh) | (force < low_force_thresh))
    else:
        loss_mask = np.zeros_like(force, dtype=bool)

    # Count contiguous episodes of "loss of balance" that last at least a short duration.
    min_event_duration = 0.2  # seconds
    min_event_frames = max(int(round(min_event_duration / dt)), 1)

    loss_count = 0
    run_length = 0
    for flag in loss_mask:
        if flag:
            run_length += 1
        else:
            if run_length >= min_event_frames:
                loss_count += 1
            run_length = 0
    if run_length >= min_event_frames:
        loss_count += 1

    return {
        "Number of Balance Losses": float(loss_count),
        "Average Pressure / Active Sensor": avg_pressure_per_sensor,
        "Baseline Area (pixels)": baseline_area,
    }


# ---------------------------
# CV / Image Processing Helpers
# ---------------------------

def _get_blobs(frame: np.ndarray) -> List[Dict]:
    """
    Detect connected components (feet) in a pressure frame using OpenCV.
    Returns list of dicts with keys: 'centroid', 'bbox', 'area'.
    """
    # Normalize frame to 0-255 uint8
    if np.max(frame) > 0:
        norm_frame = (frame / np.max(frame) * 255).astype(np.uint8)
    else:
        return []
    
    # Threshold to binary (low threshold to catch any contact)
    _, thresh = cv2.threshold(norm_frame, 5, 255, cv2.THRESH_BINARY)
    
    # Find contours
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    blobs = []
    for cnt in contours:
        area = cv2.contourArea(cnt)
        # Filter small noise (single pixels or tiny clusters)
        if area < 3: 
            continue
        
        M = cv2.moments(cnt)
        if M["m00"] != 0:
            cx = M["m10"] / M["m00"]
            cy = M["m01"] / M["m00"]
        else:
            cx, cy = 0, 0
            
        x, y, w, h = cv2.boundingRect(cnt)
        
        blobs.append({
            "centroid": (cx, cy),
            "bbox": (x, y, w, h),
            "area": area,
            "contour": cnt
        })
        
    # Sort by area descending (largest feet first)
    blobs.sort(key=lambda b: b["area"], reverse=True)
    return blobs


def _track_step_count_cv(signals: BasicMatSignals) -> Tuple[int, float]:
    """
    Count steps using blob tracking.
    Returns (step_count, first_step_time).
    """
    frames = signals.frames
    times = signals.time_s
    
    step_count = 0
    first_step_time = float("nan")
    
    # Baseline: Average of first 5 frames (or less if short)
    n_baseline = min(5, len(frames))
    baseline_blobs = []
    for i in range(n_baseline):
        blobs = _get_blobs(frames[i])
        baseline_blobs.extend(blobs[:2])
        
    if not baseline_blobs:
        return 0, float("nan")
        
    # Detection loop
    prev_centroids = [b['centroid'] for b in _get_blobs(frames[0])[:2]]
    
    in_step = False
    
    # Distance threshold (in grid units). Mat is 48x48. 
    move_thresh = 3.0 
    
    for i in range(1, len(frames)):
        curr_blobs = _get_blobs(frames[i])
        curr_centroids = [b['centroid'] for b in curr_blobs[:2]] # Track top 2
        
        if not curr_centroids:
            continue
            
        # Match current centroids to previous nearest neighbors
        moved = False
        
        for c in curr_centroids:
            # Min distance to any previous centroid
            if not prev_centroids:
                dist = 999
            else:
                dist = min(np.sqrt((c[0]-p[0])**2 + (c[1]-p[1])**2) for p in prev_centroids)
            
            if dist > move_thresh:
                moved = True
                break
                
        if moved:
            if not in_step:
                step_count += 1
                in_step = True
                if np.isnan(first_step_time):
                    first_step_time = float(times[i])
        else:
            pass
            
        prev_centroids = curr_centroids
        
        if not moved:
            in_step = False
            
    return step_count, first_step_time


# ---------------------------
# Scoring helpers
# ---------------------------

def _three_level_score(
    value: float,
    good_threshold: float,
    moderate_threshold: float,
    reverse: bool = False,
) -> int:
    """
    Map a continuous metric to {0,1,2}.
    """
    if np.isnan(value):
        return 0

    if reverse:
        if value <= good_threshold:
            return 2
        if value <= moderate_threshold:
            return 1
        return 0
    else:
        if value >= good_threshold:
            return 2
        if value >= moderate_threshold:
            return 1
        return 0


# ---------------------------
# Exercise-specific analyses
# ---------------------------

def process_compensatory_stepping(csv_path: str, direction: str, participant: str) -> ExerciseResult:
    """
    Compensatory Stepping Correction.
    """
    signals = load_basic_signals(csv_path)
    duration = _duration(signals)
    sway = _sway_metrics(signals.cop_x, signals.cop_y)
    
    # Use CV based step counting
    step_count, first_step_time = _track_step_count_cv(signals)
    
    dt = max(signals.dt, 1e-4)
    dx = np.diff(signals.cop_x)
    dy = np.diff(signals.cop_y)
    speed = np.sqrt(dx * dx + dy * dy) / dt
    window = max(int(round(0.5 / dt)), 1)
    if len(speed) >= window:
        kernel = np.ones(window) / window
        speed_smoothed = np.convolve(speed, kernel, mode="same")
        speed_thresh = 0.5
        stable_idx = np.where(speed_smoothed < speed_thresh)[0]
        stabilization_time = float(signals.time_s[stable_idx[0]]) if stable_idx.size > 0 else duration
    else:
        stabilization_time = duration

    # Scoring
    if step_count == 0:
        score = 0
    else:
        if direction == "FORWARD":
            if step_count <= 2:
                score = 2
            else:
                score = 1
        else:
            if step_count == 1:
                score = 2
            else:
                score = 1

    features = {
        "Duration (s)": duration,
        "Stabilization Time (s)": stabilization_time,
        "Reaction Time (s)": first_step_time,
        "Number of Steps (CV)": float(step_count),
        "CoP Path Length": sway.get("cop_path_length", float("nan")),
        "CoP RMS": sway.get("cop_rms", float("nan")),
    }

    return ExerciseResult(
        participant=participant,
        exercise="Compensatory stepping correction",
        variant=direction,
        file_path=csv_path,
        score=score,
        features=features,
    )


def process_rise_to_toes(csv_path: str, participant: str) -> ExerciseResult:
    """
    Rise to toes.
    Robust approach using Contact Area of valid frames only (ignoring dropouts).
    """
    signals = load_basic_signals(csv_path)
    duration = _duration(signals)
    
    area = signals.area.astype(float)
    force = signals.force
    time_s = signals.time_s
    
    # 1. Identify Active Phase (Robust to outliers/noise)
    nonzero_force = force[force > 10] # Minimal noise floor
    if len(nonzero_force) == 0:
         return ExerciseResult(participant, "Rise to toes", None, csv_path, 0, {})
         
    median_force = np.median(nonzero_force)
    active_thresh = median_force * 0.1 # 10% of median valid force
    active_mask = force > active_thresh
    
    if not np.any(active_mask):
        return ExerciseResult(participant, "Rise to toes", None, csv_path, 0, {})

    valid_area = area[active_mask]
    valid_time = time_s[active_mask]

    # 2. Determine Baseline Area (Flat Foot)
    baseline_area = float(np.percentile(valid_area, 95))
    
    # 3. Threshold for "On Toes"
    thresh_ratio = 0.80
    area_thresh = baseline_area * thresh_ratio
    
    # 4. Smooth the Area signal
    # Use a time-based window of ~0.2s for robust smoothing
    dt = max(signals.dt, 0.001)
    window_size_sec = 0.2
    window_size = max(3, int(window_size_sec / dt))
    smoothed_area = median_filter(valid_area, size=window_size)
    
    # 5. Detection
    is_on_toes = smoothed_area < area_thresh
    
    # 6. Calculate Duration
    max_run_duration = 0.0
    current_run_duration = 0.0
    
    for i in range(1, len(valid_time)):
        step_dt = valid_time[i] - valid_time[i-1]
        
        # Break run if gap is large (e.g. > 0.5s)
        if step_dt > 0.5:
            current_run_duration = 0.0
            continue
            
        if is_on_toes[i]:
            current_run_duration += step_dt
        else:
            max_run_duration = max(max_run_duration, current_run_duration)
            current_run_duration = 0.0
            
    max_run_duration = max(max_run_duration, current_run_duration)
    
    # Scoring
    if max_run_duration >= 3.0:
        score = 2
    elif max_run_duration >= 0.5:
        score = 1
    else:
        score = 0

    features = {
        "Trial Duration (s)": duration,
        "Time on Toes (s)": max_run_duration,
        "Baseline Area (pixels)": baseline_area,
        "Min Active Area (pixels)": float(np.min(valid_area)),
        "Area Threshold": area_thresh,
        "_valid_time": valid_time,         # Pass for plotting
        "_smoothed_area": smoothed_area    # Pass for plotting
    }

    return ExerciseResult(
        participant=participant,
        exercise="Rise to toes",
        variant=None,
        file_path=csv_path,
        score=score,
        features=features,
    )


def process_sit_to_stand(csv_path: str, participant: str) -> ExerciseResult:
    """
    Sit to Stand.
    """
    signals = load_basic_signals(csv_path)
    full_duration = _duration(signals)
    
    f = signals.force
    window = 10
    f_smooth = np.convolve(f, np.ones(window)/window, mode='same') if len(f) > window else f
    
    max_f = np.max(f_smooth)
    
    stable_mask = (f_smooth > 0.8 * max_f)
    time_stable = np.sum(stable_mask) * signals.dt
    
    t_start_idx = np.where(f_smooth > 0.1 * max_f)[0]
    t_end_idx = np.where(f_smooth > 0.9 * max_f)[0]
    
    if t_start_idx.size > 0 and t_end_idx.size > 0:
        start_t = signals.time_s[t_start_idx[0]]
        end_t = signals.time_s[t_end_idx[0]]
        rise_time = max(0, end_t - start_t)
    else:
        rise_time = full_duration
        
    # Scoring:
    if rise_time < 3.0 and time_stable > 2.0:
        score = 2
    elif rise_time < 6.0: 
        score = 1
    else:
        score = 0
        
    features = {
        "Stand-up Duration (s)": rise_time,
        "Time in Stable Stance (s)": time_stable,
        "Total Duration (s)": full_duration,
        "Max Force": float(max_f)
    }

    return ExerciseResult(
        participant=participant,
        exercise="Sit to Stand",
        variant=None,
        file_path=csv_path,
        score=score,
        features=features,
    )


def process_stand_on_one_leg(csv_path: str, participant: str, stance_leg: str) -> ExerciseResult:
    """
    Stand on one leg.
    """
    signals = load_basic_signals(csv_path)
    duration = _duration(signals)
    sway = _sway_metrics(signals.cop_x, signals.cop_y)

    if duration >= 20.0:
        score = 2
    elif duration >= 10.0:
        score = 1
    else:
        score = 0

    features = {
        "Duration (s)": duration,
        "CoP Path Length": sway.get("cop_path_length", float("nan")),
        "CoP RMS": sway.get("cop_rms", float("nan")),
    }

    return ExerciseResult(
        participant=participant,
        exercise="Stand on one leg",
        variant=stance_leg,
        file_path=csv_path,
        score=score,
        features=features,
    )


def process_stance_eyes_open(csv_path: str, participant: str) -> ExerciseResult:
    """Stance feet together, eyes open."""
    signals = load_basic_signals(csv_path)
    duration = _duration(signals)
    sway = _sway_metrics(signals.cop_x, signals.cop_y)
    stance_metrics = _stance_balance_metrics(signals)
    
    # --- New Step Detection Logic ---
    # A step is a failure of the stance. The effective duration is time until the first step.
    step_count, first_step_time = _track_step_count_cv(signals)
    
    if np.isnan(first_step_time):
        # No step was detected, so the person stood for the full duration
        effective_stance_duration = duration
    else:
        # A step was detected, so the stance ended at that time
        effective_stance_duration = first_step_time

    # --- New Scoring Logic ---
    if effective_stance_duration >= 30.0:
        score = 2 # Normal: stood for 30s without stepping
    elif effective_stance_duration >= 2.0:
        score = 1 # Moderate: stood for at least 2s, but stepped before 30s
    else:
        score = 0 # Severe: unable to hold stance for even 2 seconds

    features = {
        "Trial Duration (s)": duration,
        "Effective Stance Duration (s)": effective_stance_duration,
        "First Step Time (s)": first_step_time,
        "Number of Steps Detected": float(step_count),
        "Number of Balance Losses": stance_metrics.get("Number of Balance Losses", float("nan")),
        "Average Pressure / Active Sensor": stance_metrics.get("Average Pressure / Active Sensor", float("nan")),
        "Baseline Area (pixels)": stance_metrics.get("Baseline Area (pixels)", float("nan")),
        "CoP Path Length": sway.get("cop_path_length", float("nan")),
        "CoP RMS": sway.get("cop_rms", float("nan")),
    }

    return ExerciseResult(
        participant=participant,
        exercise="Stance feet together (eyes open, firm)",
        variant=None,
        file_path=csv_path,
        score=score,
        features=features,
    )


def process_stance_eyes_closed(csv_path: str, participant: str) -> ExerciseResult:
    """Stance feet together, eyes closed."""
    signals = load_basic_signals(csv_path)
    duration = _duration(signals)
    sway = _sway_metrics(signals.cop_x, signals.cop_y)
    stance_metrics = _stance_balance_metrics(signals)

    # --- New Step Detection Logic ---
    # A step is a failure of the stance. The effective duration is time until the first step.
    step_count, first_step_time = _track_step_count_cv(signals)

    if np.isnan(first_step_time):
        # No step was detected, so the person stood for the full duration
        effective_stance_duration = duration
    else:
        # A step was detected, so the stance ended at that time
        effective_stance_duration = first_step_time

    # --- New Scoring Logic ---
    if effective_stance_duration >= 30.0:
        score = 2 # Normal: stood for 30s without stepping
    elif effective_stance_duration >= 2.0:
        score = 1 # Moderate: stood for at least 2s, but stepped before 30s
    else:
        score = 0 # Severe: unable to hold stance for even 2 seconds


    features = {
        "Trial Duration (s)": duration,
        "Effective Stance Duration (s)": effective_stance_duration,
        "First Step Time (s)": first_step_time,
        "Number of Steps Detected": float(step_count),
        "Number of Balance Losses": stance_metrics.get("Number of Balance Losses", float("nan")),
        "Average Pressure / Active Sensor": stance_metrics.get("Average Pressure / Active Sensor", float("nan")),
        "Baseline Area (pixels)": stance_metrics.get("Baseline Area (pixels)", float("nan")),
        "CoP Path Length": sway.get("cop_path_length", float("nan")),
        "CoP RMS": sway.get("cop_rms", float("nan")),
    }

    return ExerciseResult(
        participant=participant,
        exercise="Stance feet together (eyes closed, foam)",
        variant=None,
        file_path=csv_path,
        score=score,
        features=features,
    )


def _infer_participant_and_exercise(root: str, filename: str) -> Tuple[str, Optional[str], Optional[str]]:
    """
    Infer participant, exercise, and variant (direction / side) from filename.
    """
    participant = os.path.basename(root)
    name = filename

    # Compensatory stepping
    if "Compensatory_stepping_correction-_BACKWARD" in name:
        return participant, "comp_stepping_backward", "BACKWARD"
    if "Compensatory_stepping_correction-_FORWARD" in name:
        return participant, "comp_stepping_forward", "FORWARD"
    if "Compensatory_stepping_correction-_LATERAL" in name and "RIGHT SIDE" in name:
        return participant, "comp_stepping_lateral_right", "LATERAL-RIGHT"
    if "Compensatory_stepping_correction-_LATERAL" in name and "LEFT SIDE" in name:
        return participant, "comp_stepping_lateral_left", "LATERAL-LEFT"

    # Rise to toes
    if "Rise_to_toes" in name:
        return participant, "rise_to_toes", None

    # Sit to stand
    if "Sit_to_stand" in name:
        return participant, "sit_to_stand", None

    # Stance eyes open / closed
    if "Stance,_Eyes_open" in name:
        return participant, "stance_eyes_open", None
    if "Stance,_Eyes_closed" in name:
        return participant, "stance_eyes_closed", None

    # Stand on one leg
    if "Stand_on_one_leg" in name and "RIGHT LEG OFF" in name:
        # Right leg off -> standing on LEFT
        return participant, "stand_one_leg_left", "Left"
    if "Stand_on_one_leg" in name and "LEFT LEG OFF" in name:
        # Left leg off -> standing on RIGHT
        return participant, "stand_one_leg_right", "Right"

    return participant, None, None


def process_all(data_root: str = ".") -> List[ExerciseResult]:
    """
    Walk through Evita / Kostas / Panos folders, process all requested exercises,
    and return a list of ExerciseResult objects.
    """
    results: List[ExerciseResult] = []

    for participant in ["Evita", "Kostas", "Panos"]:
        participant_dir = os.path.join(data_root, participant)
        if not os.path.isdir(participant_dir):
            continue

        for root, _, files in os.walk(participant_dir):
            for fname in files:
                if not fname.lower().endswith(".csv"):
                    continue

                part, ex_key, variant = _infer_participant_and_exercise(root, fname)
                if ex_key is None:
                    continue

                csv_path = os.path.join(root, fname)

                try:
                    if ex_key.startswith("comp_stepping"):
                        direction = variant or "UNKNOWN"
                        res = process_compensatory_stepping(csv_path, direction, part)
                    elif ex_key == "rise_to_toes":
                        res = process_rise_to_toes(csv_path, part)
                    elif ex_key == "sit_to_stand":
                        res = process_sit_to_stand(csv_path, part)
                    elif ex_key == "stance_eyes_open":
                        res = process_stance_eyes_open(csv_path, part)
                    elif ex_key == "stance_eyes_closed":
                        res = process_stance_eyes_closed(csv_path, part)
                    elif ex_key == "stand_one_leg_left":
                        res = process_stand_on_one_leg(csv_path, part, stance_leg="Left")
                    elif ex_key == "stand_one_leg_right":
                        res = process_stand_on_one_leg(csv_path, part, stance_leg="Right")
                    else:
                        continue

                    results.append(res)
                except Exception as e:
                    print(f"Error processing {csv_path}: {e}")
                    import traceback
                    traceback.print_exc()

    return results


def results_to_dataframe(results: List[ExerciseResult]) -> pd.DataFrame:
    """Flatten ExerciseResult objects into a pandas DataFrame."""
    rows = []
    for r in results:
        base = {
            "participant": r.participant,
            "exercise": r.exercise,
            "variant": r.variant,
            "file_path": r.file_path,
            "score": r.score,
        }
        base.update(r.features)
        rows.append(base)
    return pd.DataFrame(rows)


def main() -> None:
    results = process_all(".")
    if not results:
        print("No exercise CSVs found for Evita / Kostas / Panos.")
        return

    df = results_to_dataframe(results)
    pd.set_option("display.max_columns", None)
    pd.set_option("display.width", 160)

    print("Per-file scores:")
    print(df[["participant", "exercise", "variant", "score", "file_path"]])

    print("\nMean scores per participant and exercise:")
    summary = df.groupby(["participant", "exercise", "variant"])["score"].mean().reset_index()
    print(summary)


if __name__ == "__main__":
    main()
